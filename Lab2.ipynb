{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proyecto- Segmentación en grupos de acuerdo a características de pacientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes: Maria Fernanda De La Hoz, Silvana Sandoval y Gabriela Soler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto tiene el objetivo de incorporar herramientas de Inteligencia Artificial para incrementar la eficiencia de la prestación de servicios a los usuarios en las diferentes IPS asociadas, teniendo en cuenta que en el contexto del triage, la agrupación puede ser útil para la toma de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entendimiento de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grupo  Sexo  Edad  Modo_Llegada  Lesion  Queja_Principal  Estado_Mental  \\\n",
      "0      2     2    49             2       1  ant. chest pain              1   \n",
      "1      2     2    30             4       1         headache              1   \n",
      "2      2     1    61             3       2  ant. chest pain              1   \n",
      "3      2     2    61             3       1         headache              1   \n",
      "4      1     2    67             3       1    fever & chill              1   \n",
      "\n",
      "   Dolor dolor_NRS    SBP  ...    BT  Saturacion  KTAS_enfermera  \\\n",
      "0      1         2  150.0  ...  36.2        98.0               2   \n",
      "1      1         4  140.0  ...  36.3        99.0               3   \n",
      "2      1         3  100.0  ...  36.4        98.0               4   \n",
      "3      1         4  120.0  ...  36.5        99.0               4   \n",
      "4      0    #BOÃ!  143.0  ...  38.1         NaN               4   \n",
      "\n",
      "                Diagnostico_En_Urgencias  Disposicion  KTAS_experto  \\\n",
      "0                   Ischaemic chest pain            2             2   \n",
      "1  Subarachnoid haemorrhage, unspecified            7             3   \n",
      "2      Contusion of front wall of thorax            1             4   \n",
      "3                               Headache            1             3   \n",
      "4                                  Fever            1             2   \n",
      "\n",
      "  Grupo_De_Error  Duracion_Estancia_Min  Duracion_KTAS_Min  Error_Triaje  \n",
      "0              0                   1591               2,00             0  \n",
      "1              0                    211               3,00             0  \n",
      "2              0                    119               2,00             0  \n",
      "3              4                    414               2,00             2  \n",
      "4              1                    267               3,60             2  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"202420_Laboratorio 2 - Agrupación_202420_Laboratorio_2_-_Agrupación_data.csv\", encoding=\"latin1\", sep=\",\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Grupo         Sexo         Edad  Modo_Llegada     Lesion  \\\n",
      "count  1000.000000  1000.000000  1000.000000   1000.000000  1000.0000   \n",
      "mean      1.450000     1.514000    53.892000      2.811000     1.2000   \n",
      "std       0.497743     0.500054    19.826483      0.796186     0.4002   \n",
      "min       1.000000     1.000000    16.000000      1.000000     1.0000   \n",
      "25%       1.000000     1.000000    36.000000      2.000000     1.0000   \n",
      "50%       1.000000     2.000000    56.000000      3.000000     1.0000   \n",
      "75%       2.000000     2.000000    70.250000      3.000000     1.0000   \n",
      "max       2.000000     2.000000    94.000000      7.000000     2.0000   \n",
      "\n",
      "       Estado_Mental        Dolor         SBP         DBP          HR  \\\n",
      "count    1000.000000  1000.000000  983.000000  979.000000  988.000000   \n",
      "mean        1.103000     0.562000  133.485249   79.566905   84.400810   \n",
      "std         0.431946     0.496389   27.156136   15.174593   16.297428   \n",
      "min         1.000000     0.000000   50.000000   31.000000   32.000000   \n",
      "25%         1.000000     0.000000  114.000000   70.000000   73.000000   \n",
      "50%         1.000000     1.000000  130.000000   80.000000   82.000000   \n",
      "75%         1.000000     1.000000  150.000000   90.000000   96.000000   \n",
      "max         4.000000     1.000000  275.000000  160.000000  148.000000   \n",
      "\n",
      "               RR          BT  Saturacion  KTAS_enfermera  Disposicion  \\\n",
      "count  985.000000  989.000000  444.000000     1000.000000  1000.000000   \n",
      "mean    19.450761   36.562993   97.047297        3.328000     1.610000   \n",
      "std      2.069882    0.519699    4.761112        0.862067     1.161572   \n",
      "min     14.000000   35.000000   20.000000        1.000000     1.000000   \n",
      "25%     18.000000   36.200000   97.000000        3.000000     1.000000   \n",
      "50%     20.000000   36.500000   98.000000        3.000000     1.000000   \n",
      "75%     20.000000   36.800000   99.000000        4.000000     2.000000   \n",
      "max     30.000000   39.800000  100.000000        5.000000     7.000000   \n",
      "\n",
      "       KTAS_experto  Grupo_De_Error  Duracion_Estancia_Min  Error_Triaje  \n",
      "count   1000.000000     1000.000000            1000.000000   1000.000000  \n",
      "mean       3.260000        0.569000           12792.480000      0.253000  \n",
      "std        0.865534        1.587375           87721.151446      0.630387  \n",
      "min        1.000000        0.000000               0.000000      0.000000  \n",
      "25%        3.000000        0.000000             132.750000      0.000000  \n",
      "50%        3.000000        0.000000             270.500000      0.000000  \n",
      "75%        4.000000        0.000000             620.000000      0.000000  \n",
      "max        5.000000        9.000000          709510.000000      2.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de las variables para la implementación del proyecto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Variables Categóricas:*\n",
    "\n",
    "Grupo: Es una variable importante porque parece clasificar a los pacientes en grupos que queremos optimizar.\n",
    "\n",
    "Sexo, Modo_Llegada, Lesión, Estado_Mental, Dolor: Estas variables categorizadas probablemente influyan en la clasificación y deberían codificarse adecuadamente.\n",
    "\n",
    "*Variables de Severidad:*\n",
    "KTAS_Enfermera y KTAS_Experto: Estas escalas son importantes para evaluar la urgencia de los pacientes. Es clave tenerlas en cuenta en el modelo de agrupamiento.\n",
    "\n",
    "Disposición: Esta variable refleja qué pasó con el paciente después de la evaluación, lo que podría ser útil para encontrar patrones en los resultados del tratamiento.\n",
    "\n",
    "*Variables Numéricas:*\n",
    "\n",
    "Las variables fisiológicas como SBP (Presión Arterial Sistólica), DBP (Presión Diastólica), HR (Frecuencia Cardíaca), RR (Frecuencia Respiratoria), BT (Temperatura Corporal), y Saturación (Oxígeno) son críticas para describir el estado físico del paciente.\n",
    "\n",
    "Variables de tiempo como Duración_Estancia_Min y Duración_KTAS_Min también son importantes porque podrían ayudar a analizar la eficiencia de la atención.\n",
    "\n",
    "*Variables que podrían tener ruido:*\n",
    "\n",
    "Grupo_Error, Error_Triaje: Si estamos trabajando para hacer agrupamientos basados en la condición de los pacientes, estas columnas relacionadas con errores podrían introducir ruido o ser útiles para analizar el rendimiento de los grupos predichos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manejo de variables faltantes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las variables críticas (por ejemplo, las fisiológicas y de severidad), podemos usar imputación. Es por esto que identificaremos cuáles columnas tienen valores faltantes y cuántos faltan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grupo                         0\n",
       "Sexo                          0\n",
       "Edad                          0\n",
       "Modo_Llegada                  0\n",
       "Lesion                        0\n",
       "Queja_Principal               0\n",
       "Estado_Mental                 0\n",
       "Dolor                         0\n",
       "dolor_NRS                     0\n",
       "SBP                          17\n",
       "DBP                          21\n",
       "HR                           12\n",
       "RR                           15\n",
       "BT                           11\n",
       "Saturacion                  556\n",
       "KTAS_enfermera                0\n",
       "Diagnostico_En_Urgencias      1\n",
       "Disposicion                   0\n",
       "KTAS_experto                  0\n",
       "Grupo_De_Error                0\n",
       "Duracion_Estancia_Min         0\n",
       "Duracion_KTAS_Min             0\n",
       "Error_Triaje                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las variables fisiológicas con pocos valores faltantes (SBP, DBP, HR, RR, BT):\n",
    "Podemos usar imputación con la mediana. La mediana es robusta a valores atípicos y adecuada para variables fisiológicas.\n",
    "\n",
    "Para la variable Saturacion, que tiene más del 50% de los datos faltantes:\n",
    "Podríamos considerar imputar con la mediana también, pero como tiene demasiados valores faltantes, otra opción sería eliminar esta columna si no es esencial para el análisis.\n",
    "\n",
    "Para Diagnostico_En_Urgencias, que tiene solo un valor faltante:\n",
    "Imputar con el valor más frecuente será una estrategia razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciaremos creando una copia de los datos para realizar un preprocesamiento\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['SBP'].fillna(data_copy['SBP'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['DBP'].fillna(data_copy['DBP'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['HR'].fillna(data_copy['HR'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['RR'].fillna(data_copy['RR'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['BT'].fillna(data_copy['BT'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['Saturacion'].fillna(data_copy['Saturacion'].median(), inplace=True)\n",
      "C:\\Users\\Mafe\\AppData\\Local\\Temp\\ipykernel_13044\\3558805917.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_copy['Diagnostico_En_Urgencias'].fillna(data_copy['Diagnostico_En_Urgencias'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Imputar las variables fisiológicas con la mediana\n",
    "data_copy['SBP'].fillna(data_copy['SBP'].median(), inplace=True)\n",
    "data_copy['DBP'].fillna(data_copy['DBP'].median(), inplace=True)\n",
    "data_copy['HR'].fillna(data_copy['HR'].median(), inplace=True)\n",
    "data_copy['RR'].fillna(data_copy['RR'].median(), inplace=True)\n",
    "data_copy['BT'].fillna(data_copy['BT'].median(), inplace=True)\n",
    "\n",
    "# Para la saturación, decidimos imputar con la mediana\n",
    "data_copy['Saturacion'].fillna(data_copy['Saturacion'].median(), inplace=True)\n",
    "\n",
    "# Imputar el Diagnóstico en Urgencias con el valor más frecuente\n",
    "data_copy['Diagnostico_En_Urgencias'].fillna(data_copy['Diagnostico_En_Urgencias'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo                       0\n",
      "Sexo                        0\n",
      "Edad                        0\n",
      "Modo_Llegada                0\n",
      "Lesion                      0\n",
      "Queja_Principal             0\n",
      "Estado_Mental               0\n",
      "Dolor                       0\n",
      "dolor_NRS                   0\n",
      "SBP                         0\n",
      "DBP                         0\n",
      "HR                          0\n",
      "RR                          0\n",
      "BT                          0\n",
      "Saturacion                  0\n",
      "KTAS_enfermera              0\n",
      "Diagnostico_En_Urgencias    0\n",
      "Disposicion                 0\n",
      "KTAS_experto                0\n",
      "Grupo_De_Error              0\n",
      "Duracion_Estancia_Min       0\n",
      "Duracion_KTAS_Min           0\n",
      "Error_Triaje                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_copy.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que solucionamos el problema de las variables faltantes, procederemos al tratamiento de las variables categóricas. Como los algoritmos de agrupamiento requieren variables numéricas, vamos a convertir las variables categóricas a un formato numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos Label Encoding para variables ordinales como KTAS_Enfermera, Estado_Mental, y Disposición, donde los valores tienen un orden implícito, y One-Hot Encoding para variables nominales como Modo_Llegada y Lesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_copy['KTAS_Enfermera'] = le.fit_transform(data_copy['KTAS_enfermera'])\n",
    "data_copy['Estado_Mental'] = le.fit_transform(data_copy['Estado_Mental'])\n",
    "data_copy['Disposición'] = le.fit_transform(data_copy['Disposicion'])\n",
    "\n",
    "data_copy = pd.get_dummies(data, columns=['Modo_Llegada', 'Lesion', 'Sexo'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grupo  Edad  Queja_Principal  Estado_Mental  Dolor dolor_NRS    SBP   DBP  \\\n",
      "0      2    49  ant. chest pain              1      1         2  150.0  90.0   \n",
      "1      2    30         headache              1      1         4  140.0  80.0   \n",
      "2      2    61  ant. chest pain              1      1         3  100.0  60.0   \n",
      "3      2    61         headache              1      1         4  120.0  70.0   \n",
      "4      1    67    fever & chill              1      0    #BOÃ!  143.0  70.0   \n",
      "\n",
      "      HR    RR  ...  Duracion_KTAS_Min  Error_Triaje  Modo_Llegada_2  \\\n",
      "0   92.0  20.0  ...               2,00             0            True   \n",
      "1   76.0  20.0  ...               3,00             0           False   \n",
      "2   84.0  20.0  ...               2,00             0           False   \n",
      "3   76.0  20.0  ...               2,00             2           False   \n",
      "4  130.0  20.0  ...               3,60             2           False   \n",
      "\n",
      "  Modo_Llegada_3  Modo_Llegada_4  Modo_Llegada_5  Modo_Llegada_6  \\\n",
      "0          False           False           False           False   \n",
      "1          False            True           False           False   \n",
      "2           True           False           False           False   \n",
      "3           True           False           False           False   \n",
      "4           True           False           False           False   \n",
      "\n",
      "   Modo_Llegada_7 Lesion_2  Sexo_2  \n",
      "0           False    False    True  \n",
      "1           False    False    True  \n",
      "2           False     True   False  \n",
      "3           False    False    True  \n",
      "4           False    False    True  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al revisar los datos podemos ver que hay algunas entradas que tienen \",\" en lugar de \".\", los que generará un problema en la normalización de los datos. Por lo que es necesario remplazar este carácter y convertir el formato del dato a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar comas por puntos en las columnas que contienen números decimales almacenados como texto\n",
    "data_copy['Duracion_KTAS_Min'] = data_copy['Duracion_KTAS_Min'].str.replace(',', '.').astype(float)\n",
    "data_copy['dolor_NRS'] = data_copy['dolor_NRS'].replace(',', '.', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procederemos a realizar una normalización de los datos, puesto que las variables numéricas deben estar en una escala común, especialmente si estamos implementando un algoritmo basado en distancias, como K-means. Es por esto, que normalizaremos las variables fisiológicas, de tiempo, y de edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grupo      Edad  Queja_Principal  Estado_Mental  Dolor dolor_NRS       SBP  \\\n",
      "0      2  0.423077  ant. chest pain              1      1         2  0.444444   \n",
      "1      2  0.179487         headache              1      1         4  0.400000   \n",
      "2      2  0.576923  ant. chest pain              1      1         3  0.222222   \n",
      "3      2  0.576923         headache              1      1         4  0.311111   \n",
      "4      1  0.653846    fever & chill              1      0    #BOÃ!  0.413333   \n",
      "\n",
      "        DBP        HR     RR  ...  Duracion_KTAS_Min  Error_Triaje  \\\n",
      "0  0.457364  0.517241  0.375  ...           0.061087             0   \n",
      "1  0.379845  0.379310  0.375  ...           0.122175             0   \n",
      "2  0.224806  0.448276  0.375  ...           0.061087             0   \n",
      "3  0.302326  0.379310  0.375  ...           0.061087             2   \n",
      "4  0.302326  0.844828  0.375  ...           0.158827             2   \n",
      "\n",
      "   Modo_Llegada_2 Modo_Llegada_3  Modo_Llegada_4  Modo_Llegada_5  \\\n",
      "0            True          False           False           False   \n",
      "1           False          False            True           False   \n",
      "2           False           True           False           False   \n",
      "3           False           True           False           False   \n",
      "4           False           True           False           False   \n",
      "\n",
      "   Modo_Llegada_6  Modo_Llegada_7  Lesion_2  Sexo_2  \n",
      "0           False           False     False    True  \n",
      "1           False           False     False    True  \n",
      "2           False           False      True   False  \n",
      "3           False           False     False    True  \n",
      "4           False           False     False    True  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seleccionar las columnas numéricas que queremos normalizar\n",
    "numerical_cols = ['Edad', 'SBP', 'DBP', 'HR', 'RR', 'BT', 'Saturacion', 'Duracion_Estancia_Min', 'Duracion_KTAS_Min']\n",
    "\n",
    "# Inicializar el escalador Min-Max y aplicar\n",
    "scaler = MinMaxScaler()\n",
    "data_copy[numerical_cols] = scaler.fit_transform(data_copy[numerical_cols])\n",
    "\n",
    "# Revisar los datos normalizados\n",
    "print(data_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos limpiado y preparado los datos, podemos proceder a implementar un modelo de agrupamiento. Para empezar, vamos a usar K-means para ver si podemos identificar grupos de pacientes con características similares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ant. chest pain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(data_copy)\n\u001b[0;32m      7\u001b[0m data_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \n\u001b[0;32m   1440\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1465\u001b[0m         X,\n\u001b[0;32m   1466\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1467\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[0;32m   1468\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1469\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[0;32m   1470\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m   1475\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 929\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    931\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Mafe\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ant. chest pain'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "kmeans.fit(data_copy)\n",
    "data_copy['Cluster'] = kmeans.labels_\n",
    "\n",
    "print(data_copy['Cluster'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
